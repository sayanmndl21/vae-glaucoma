{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models \n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import latent_plot as lp\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import copy\n",
    "#from model import VAE\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "from data_loader import *\n",
    "#from model import convVAE\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only on validation set\n",
    "csv_path = '/home/vip/sayan-mandal/datasets/obj_criteria/20200619-objective.csv'\n",
    "img_path = '/home/vip/sayan-mandal/datasets/obj_criteria/good_reduced/'\n",
    "\n",
    "ResizeParam = 128\n",
    "FD = FullDataLoader(csv_path, img_path,transform=transforms.Compose([transforms.Resize(ResizeParam), transforms.RandomHorizontalFlip(p=0.5) ,transforms.ToTensor()]))\n",
    "FD2 = FullDataLoader(csv_path, img_path,transform=transforms.Compose([transforms.Resize(ResizeParam), transforms.ToTensor()]))\n",
    "\n",
    "#random sampler\n",
    "batch_size = 64\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(FD)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "val_indices =  indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(FD, batch_size=batch_size, sampler=train_sampler)\n",
    "data_loader = torch.utils.data.DataLoader(FD2, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class convVAE(nn.Module):\n",
    "    def __init__(self, in_shape, n_latent):\n",
    "        super(convVAE, self).__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.lin_shape = 16\n",
    "        self.n_latent = n_latent\n",
    "        c,h,w = in_shape\n",
    "        self.z_dim = h//2**2 # receptive field downsampled 3 times\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(c, 16, kernel_size=3, stride=1, padding=1),  # 16, 128, 128\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 32, 64, 64\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 64, 64, 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, self.lin_shape, kernel_size=3, stride=2, padding=1),  # 16, 32, 32\n",
    "            nn.BatchNorm2d(self.lin_shape),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.lin_shape * (self.z_dim)**2, 2048*2),\n",
    "            nn.BatchNorm1d(2048*2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear( 2048*2,n_latent),\n",
    "            nn.BatchNorm1d(n_latent),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.fc21 = nn.Sequential(\n",
    "            nn.Linear(n_latent, n_latent),\n",
    "        )\n",
    "        self.fc22 = nn.Sequential(\n",
    "            nn.Linear(n_latent, n_latent),\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(n_latent, n_latent*2),\n",
    "            nn.BatchNorm1d(n_latent*2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_latent*2, self.lin_shape * (self.z_dim)**2),\n",
    "            nn.BatchNorm1d(self.lin_shape * (self.z_dim)**2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.lin_shape, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def sample_z(self, mean, logvar):\n",
    "        stddev = logvar.mul(0.5).cuda()\n",
    "        noise = Variable(torch.randn(*mean.size())).cuda()\n",
    "        return (noise * stddev) + mean\n",
    "\n",
    "    def bottleneck(self, h):\n",
    "        h = self.fc1(h)\n",
    "        mean, logvar = self.fc21(h), self.fc22(h)\n",
    "        z = self.sample_z(mean, logvar)\n",
    "        return z, mean, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z, mean, logvar = self.bottleneck(x)\n",
    "        return z, mean, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        out = self.fc3(z)\n",
    "        out = out.view(out.shape[0], self.lin_shape, self.z_dim,self.z_dim)\n",
    "        out = self.decoder(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        z,mean, logvar = self.encode(x)\n",
    "        out = self.decode(z)\n",
    "        return out, z,mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "convVAE(\n  (encoder): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): Conv2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): LeakyReLU(negative_slope=0.01)\n    (12): Flatten(start_dim=1, end_dim=-1)\n  )\n  (fc1): Sequential(\n    (0): Linear(in_features=16384, out_features=4096, bias=True)\n    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Linear(in_features=4096, out_features=2048, bias=True)\n    (4): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n  )\n  (fc21): Sequential(\n    (0): Linear(in_features=2048, out_features=2048, bias=True)\n  )\n  (fc22): Sequential(\n    (0): Linear(in_features=2048, out_features=2048, bias=True)\n  )\n  (fc3): Sequential(\n    (0): Linear(in_features=2048, out_features=4096, bias=True)\n    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Linear(in_features=4096, out_features=16384, bias=True)\n    (4): BatchNorm1d(16384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n  )\n  (decoder): Sequential(\n    (0): ConvTranspose2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): Sigmoid()\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "#vae model structure\n",
    "nl = 2048\n",
    "model = convVAE((3,128,128),nl).cuda()\n",
    "model.load_state_dict(torch.load('/home/vip/sayan-mandal/vae-convmodels/dfcmmdvae_inp128_nl'+str(nl)+'_a1b1_1.torch'))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data,l1,l2,l3,l4,l5,l6,l7,l8,l9,l10) in enumerate(data_loader):\n",
    "    y, _,_ =  model.encode(Variable(data).cuda())\n",
    "    y = y.cpu().detach().numpy()\n",
    "    if i == 0:\n",
    "        yd = y\n",
    "        lbl1,lbl2,lbl3,lbl4,lbl5,lbl6,lbl7,lbl8,lbl9,lbl10 = l1.numpy(),l2.numpy(),l3.numpy(),l4.numpy(),l5.numpy(),l6.numpy(),l7.numpy(),l8.numpy(),l9.numpy(),l10.numpy()\n",
    "    else:\n",
    "        yd = np.append(yd,y,axis=0)\n",
    "        lbl1 = np.append(lbl1,l1.numpy(), axis=0)\n",
    "        lbl2= np.append(lbl2,l2.numpy(), axis=0)\n",
    "        lbl3= np.append(lbl3,l3.numpy(), axis=0)\n",
    "        lbl4= np.append(lbl4,l4.numpy(), axis=0)\n",
    "        lbl5= np.append(lbl5,l5.numpy(), axis=0)\n",
    "        lbl6= np.append(lbl6,l6.numpy(), axis=0)\n",
    "        lbl7= np.append(lbl7,l7.numpy(), axis=0)\n",
    "        lbl8= np.append(lbl8,l8.numpy(), axis=0)\n",
    "        lbl9= np.append(lbl9,l9.numpy(), axis=0)\n",
    "        lbl10 = np.append(lbl10,l10.numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1725, 2048)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "yd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl1 = lbl1.reshape(-1,1)\n",
    "lbl2 = lbl2.reshape(-1,1)\n",
    "lbl3 = lbl3.reshape(-1,1)\n",
    "lbl4 = lbl4.reshape(-1,1)\n",
    "lbl5 = lbl5.reshape(-1,1)\n",
    "lbl6 = lbl6.reshape(-1,1)\n",
    "lbl7 = lbl7.reshape(-1,1)\n",
    "lbl8 = lbl8.reshape(-1,1)\n",
    "lbl9 = lbl9.reshape(-1,1)\n",
    "lbl10 = lbl10.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['class','mdprob','psdprob','md_inf','md_sup','rnfl_g','rnfl_ti','rnfl_ni','rnfl_ts','rnfl_ns']\n",
    "for i in range(2048):\n",
    "    cols += ['ls_'+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_df = np.concatenate((lbl1,lbl2,lbl3,lbl4,lbl5,lbl6,lbl7,lbl8,lbl9,lbl10,yd),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=to_df, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      class  mdprob  psdprob  md_inf  md_sup  rnfl_g  rnfl_ti  rnfl_ni  \\\n",
       "0       1.0     0.0      2.0     0.0     0.0     2.0      2.0      0.0   \n",
       "1       0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "2       0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "3       0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "4       0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "...     ...     ...      ...     ...     ...     ...      ...      ...   \n",
       "1720    0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "1721    0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "1722    0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "1723    0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "1724    0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "\n",
       "      rnfl_ts  rnfl_ns  ...   ls_2038   ls_2039   ls_2040   ls_2041   ls_2042  \\\n",
       "0         2.0      1.0  ...  0.018631 -0.007593 -0.024147  0.034430  0.003646   \n",
       "1         0.0      0.0  ... -0.024525 -0.046875 -0.050352  0.003578 -0.048082   \n",
       "2         0.0      0.0  ...  0.044626  0.037597 -0.027641  0.000538 -0.005712   \n",
       "3         0.0      0.0  ...  0.030876 -0.001552  0.023457 -0.064065 -0.040672   \n",
       "4         0.0      0.0  ...  0.014986 -0.030513 -0.049505  0.005362  0.001994   \n",
       "...       ...      ...  ...       ...       ...       ...       ...       ...   \n",
       "1720      0.0      0.0  ...  0.000302  0.038264 -0.021580  0.025392  0.110911   \n",
       "1721      0.0      0.0  ... -0.017061 -0.070867 -0.015031  0.033257  0.016174   \n",
       "1722      0.0      0.0  ...  0.004930  0.140802  0.097778 -0.033529 -0.003383   \n",
       "1723      0.0      0.0  ... -0.008664  0.085284  0.020767  0.017655 -0.121980   \n",
       "1724      0.0      0.0  ... -0.037597 -0.063276  0.001544 -0.051610  0.064803   \n",
       "\n",
       "       ls_2043   ls_2044   ls_2045   ls_2046   ls_2047  \n",
       "0    -0.018710 -0.049644  0.004734 -0.016967 -0.035527  \n",
       "1     0.049293 -0.013819  0.046886  0.003239  0.017171  \n",
       "2     0.079605 -0.062455 -0.032286  0.055590  0.017471  \n",
       "3     0.055315  0.042166 -0.000111 -0.023842  0.041734  \n",
       "4    -0.003847 -0.019154  0.030369  0.007398 -0.031057  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1720  0.067325  0.029738 -0.097960  0.000255 -0.009319  \n",
       "1721  0.017757 -0.011400  0.004925  0.017435  0.037697  \n",
       "1722 -0.025709  0.032572 -0.061165  0.030953  0.030013  \n",
       "1723  0.042989 -0.018107 -0.005454  0.027331  0.099162  \n",
       "1724 -0.088310  0.094013  0.065418 -0.009196 -0.033197  \n",
       "\n",
       "[1725 rows x 2058 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>mdprob</th>\n      <th>psdprob</th>\n      <th>md_inf</th>\n      <th>md_sup</th>\n      <th>rnfl_g</th>\n      <th>rnfl_ti</th>\n      <th>rnfl_ni</th>\n      <th>rnfl_ts</th>\n      <th>rnfl_ns</th>\n      <th>...</th>\n      <th>ls_2038</th>\n      <th>ls_2039</th>\n      <th>ls_2040</th>\n      <th>ls_2041</th>\n      <th>ls_2042</th>\n      <th>ls_2043</th>\n      <th>ls_2044</th>\n      <th>ls_2045</th>\n      <th>ls_2046</th>\n      <th>ls_2047</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.018631</td>\n      <td>-0.007593</td>\n      <td>-0.024147</td>\n      <td>0.034430</td>\n      <td>0.003646</td>\n      <td>-0.018710</td>\n      <td>-0.049644</td>\n      <td>0.004734</td>\n      <td>-0.016967</td>\n      <td>-0.035527</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.024525</td>\n      <td>-0.046875</td>\n      <td>-0.050352</td>\n      <td>0.003578</td>\n      <td>-0.048082</td>\n      <td>0.049293</td>\n      <td>-0.013819</td>\n      <td>0.046886</td>\n      <td>0.003239</td>\n      <td>0.017171</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.044626</td>\n      <td>0.037597</td>\n      <td>-0.027641</td>\n      <td>0.000538</td>\n      <td>-0.005712</td>\n      <td>0.079605</td>\n      <td>-0.062455</td>\n      <td>-0.032286</td>\n      <td>0.055590</td>\n      <td>0.017471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.030876</td>\n      <td>-0.001552</td>\n      <td>0.023457</td>\n      <td>-0.064065</td>\n      <td>-0.040672</td>\n      <td>0.055315</td>\n      <td>0.042166</td>\n      <td>-0.000111</td>\n      <td>-0.023842</td>\n      <td>0.041734</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.014986</td>\n      <td>-0.030513</td>\n      <td>-0.049505</td>\n      <td>0.005362</td>\n      <td>0.001994</td>\n      <td>-0.003847</td>\n      <td>-0.019154</td>\n      <td>0.030369</td>\n      <td>0.007398</td>\n      <td>-0.031057</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1720</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000302</td>\n      <td>0.038264</td>\n      <td>-0.021580</td>\n      <td>0.025392</td>\n      <td>0.110911</td>\n      <td>0.067325</td>\n      <td>0.029738</td>\n      <td>-0.097960</td>\n      <td>0.000255</td>\n      <td>-0.009319</td>\n    </tr>\n    <tr>\n      <th>1721</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.017061</td>\n      <td>-0.070867</td>\n      <td>-0.015031</td>\n      <td>0.033257</td>\n      <td>0.016174</td>\n      <td>0.017757</td>\n      <td>-0.011400</td>\n      <td>0.004925</td>\n      <td>0.017435</td>\n      <td>0.037697</td>\n    </tr>\n    <tr>\n      <th>1722</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.004930</td>\n      <td>0.140802</td>\n      <td>0.097778</td>\n      <td>-0.033529</td>\n      <td>-0.003383</td>\n      <td>-0.025709</td>\n      <td>0.032572</td>\n      <td>-0.061165</td>\n      <td>0.030953</td>\n      <td>0.030013</td>\n    </tr>\n    <tr>\n      <th>1723</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.008664</td>\n      <td>0.085284</td>\n      <td>0.020767</td>\n      <td>0.017655</td>\n      <td>-0.121980</td>\n      <td>0.042989</td>\n      <td>-0.018107</td>\n      <td>-0.005454</td>\n      <td>0.027331</td>\n      <td>0.099162</td>\n    </tr>\n    <tr>\n      <th>1724</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.037597</td>\n      <td>-0.063276</td>\n      <td>0.001544</td>\n      <td>-0.051610</td>\n      <td>0.064803</td>\n      <td>-0.088310</td>\n      <td>0.094013</td>\n      <td>0.065418</td>\n      <td>-0.009196</td>\n      <td>-0.033197</td>\n    </tr>\n  </tbody>\n</table>\n<p>1725 rows Ã— 2058 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('latentdat.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}