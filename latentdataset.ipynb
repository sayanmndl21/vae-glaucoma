{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models \n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import latent_plot as lp\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import copy\n",
    "#from model import VAE\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "from data_loader import *\n",
    "from model import convVAE\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only on validation set\n",
    "csv_path = '/home/vip/sayan-mandal/datasets/obj_criteria/20200619-objective.csv'\n",
    "img_path = '/home/vip/sayan-mandal/datasets/obj_criteria/good_reduced/'\n",
    "\n",
    "ResizeParam = 128\n",
    "FD = FullDataLoader(csv_path, img_path,transform=transforms.Compose([transforms.Resize(ResizeParam), transforms.RandomHorizontalFlip(p=0.5) ,transforms.ToTensor()]))\n",
    "FD2 = FullDataLoader(csv_path, img_path,transform=transforms.Compose([transforms.Resize(ResizeParam), transforms.ToTensor()]))\n",
    "\n",
    "#random sampler\n",
    "batch_size = 64\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(FD)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "val_indices =  indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(FD, batch_size=batch_size, sampler=train_sampler)\n",
    "data_loader = torch.utils.data.DataLoader(FD2, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "convVAE(\n  (encoder): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): Conv2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): LeakyReLU(negative_slope=0.01)\n    (12): Flatten(start_dim=1, end_dim=-1)\n  )\n  (fc1): Sequential(\n    (0): Linear(in_features=16384, out_features=4096, bias=True)\n    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Linear(in_features=4096, out_features=64, bias=True)\n    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n  )\n  (fc21): Sequential(\n    (0): Linear(in_features=64, out_features=64, bias=True)\n  )\n  (fc22): Sequential(\n    (0): Linear(in_features=64, out_features=64, bias=True)\n  )\n  (fc3): Sequential(\n    (0): Linear(in_features=64, out_features=128, bias=True)\n    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Linear(in_features=128, out_features=16384, bias=True)\n    (4): BatchNorm1d(16384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n  )\n  (decoder): Sequential(\n    (0): ConvTranspose2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): Sigmoid()\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "#vae model structure\n",
    "nl = 64\n",
    "model = convVAE((3,128,128),nl).cuda()\n",
    "model.load_state_dict(torch.load('/home/vip/sayan-mandal/vae-convmodels/dfcvae_inp128_nl'+str(nl)+'_a1b1.torch'))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data,l1,l2,l3,l4,l5,l6,l7,l8,l9,l10) in enumerate(data_loader):\n",
    "    y, _,_ =  model.encode(Variable(data).cuda())\n",
    "    y = y.cpu().detach().numpy()\n",
    "    if i == 0:\n",
    "        yd = y\n",
    "        lbl1,lbl2,lbl3,lbl4,lbl5,lbl6,lbl7,lbl8,lbl9,lbl10 = l1.numpy(),l2.numpy(),l3.numpy(),l4.numpy(),l5.numpy(),l6.numpy(),l7.numpy(),l8.numpy(),l9.numpy(),l10.numpy()\n",
    "    else:\n",
    "        yd = np.append(yd,y,axis=0)\n",
    "        lbl1 = np.append(lbl1,l1.numpy(), axis=0)\n",
    "        lbl2= np.append(lbl2,l2.numpy(), axis=0)\n",
    "        lbl3= np.append(lbl3,l3.numpy(), axis=0)\n",
    "        lbl4= np.append(lbl4,l4.numpy(), axis=0)\n",
    "        lbl5= np.append(lbl5,l5.numpy(), axis=0)\n",
    "        lbl6= np.append(lbl6,l6.numpy(), axis=0)\n",
    "        lbl7= np.append(lbl7,l7.numpy(), axis=0)\n",
    "        lbl8= np.append(lbl8,l8.numpy(), axis=0)\n",
    "        lbl9= np.append(lbl9,l9.numpy(), axis=0)\n",
    "        lbl10 = np.append(lbl10,l10.numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1725, 64)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "yd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl1 = lbl1.reshape(-1,1)\n",
    "lbl2 = lbl2.reshape(-1,1)\n",
    "lbl3 = lbl3.reshape(-1,1)\n",
    "lbl4 = lbl4.reshape(-1,1)\n",
    "lbl5 = lbl5.reshape(-1,1)\n",
    "lbl6 = lbl6.reshape(-1,1)\n",
    "lbl7 = lbl7.reshape(-1,1)\n",
    "lbl8 = lbl8.reshape(-1,1)\n",
    "lbl9 = lbl9.reshape(-1,1)\n",
    "lbl10 = lbl10.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['class','mdprob','psdprob','md_inf','md_sup','rnfl_g','rnfl_ti','rnfl_ni','rnfl_ts','rnfl_ns']\n",
    "for i in range(yd.shape[1]):\n",
    "    cols += ['ls_'+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_df = np.concatenate((lbl1,lbl2,lbl3,lbl4,lbl5,lbl6,lbl7,lbl8,lbl9,lbl10,yd),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=to_df, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      class  mdprob  psdprob  md_inf  md_sup  rnfl_g  rnfl_ti  rnfl_ni  \\\n",
       "0       1.0     4.0      5.0     2.0     0.0     2.0      2.0      0.0   \n",
       "1       0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "2       1.0     5.0      5.0     4.0     4.0     2.0      2.0      0.0   \n",
       "3       0.0     3.0      0.0     4.0     2.0     0.0      0.0      0.0   \n",
       "4       0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "...     ...     ...      ...     ...     ...     ...      ...      ...   \n",
       "1720    0.0     1.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "1721    0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "1722    1.0     5.0      5.0     4.0     4.0     0.0      2.0      0.0   \n",
       "1723    0.0     0.0      0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "1724    1.0     0.0      3.0     0.0     2.0     0.0      2.0      0.0   \n",
       "\n",
       "      rnfl_ts  rnfl_ns  ...     ls_54     ls_55     ls_56     ls_57     ls_58  \\\n",
       "0         1.0      1.0  ... -0.312521 -0.000666  0.285729  0.110068 -0.008065   \n",
       "1         0.0      0.0  ... -0.117288 -0.126811 -0.000619  0.109642  0.230750   \n",
       "2         2.0      0.0  ... -0.088064 -0.010177  0.039213 -0.105073 -0.464175   \n",
       "3         0.0      0.0  ...  0.003085  0.340534  0.184257 -0.344518  0.000413   \n",
       "4         0.0      0.0  ...  0.120189 -0.053361  0.002549  0.081047  0.074008   \n",
       "...       ...      ...  ...       ...       ...       ...       ...       ...   \n",
       "1720      0.0      0.0  ... -0.134965  0.009408 -0.208372 -0.118267  0.111946   \n",
       "1721      0.0      0.0  ... -0.017197  0.063621 -0.208461  0.278269  0.035245   \n",
       "1722      0.0      0.0  ...  0.292122 -0.107703  0.033369 -0.129890  0.117992   \n",
       "1723      0.0      0.0  ... -0.168297 -0.051984 -0.241973  0.068978 -0.117036   \n",
       "1724      0.0      0.0  ...  0.110091  0.072627  0.110446  0.156720 -0.054317   \n",
       "\n",
       "         ls_59     ls_60     ls_61     ls_62     ls_63  \n",
       "0     0.102690  0.218448  0.273025  0.532382 -0.312450  \n",
       "1     0.272240 -0.040699  0.440407  0.173828 -0.013333  \n",
       "2     0.165550 -0.085636 -0.486083  0.184655  0.122371  \n",
       "3    -0.457679 -0.179798  0.334319  0.014013 -0.048084  \n",
       "4     0.132922 -0.024197 -0.184508  0.065893  0.053854  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1720  0.184245  0.199419  0.077554  0.102339  0.229039  \n",
       "1721 -0.191154 -0.037291 -0.075631 -0.166058 -0.197916  \n",
       "1722  0.343188 -0.162703  0.123009 -0.177615  0.134538  \n",
       "1723 -0.083507 -0.025199  0.517580  0.146653 -0.223473  \n",
       "1724 -0.149864  0.203075 -0.032259  0.346316 -0.257093  \n",
       "\n",
       "[1725 rows x 74 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>mdprob</th>\n      <th>psdprob</th>\n      <th>md_inf</th>\n      <th>md_sup</th>\n      <th>rnfl_g</th>\n      <th>rnfl_ti</th>\n      <th>rnfl_ni</th>\n      <th>rnfl_ts</th>\n      <th>rnfl_ns</th>\n      <th>...</th>\n      <th>ls_54</th>\n      <th>ls_55</th>\n      <th>ls_56</th>\n      <th>ls_57</th>\n      <th>ls_58</th>\n      <th>ls_59</th>\n      <th>ls_60</th>\n      <th>ls_61</th>\n      <th>ls_62</th>\n      <th>ls_63</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>-0.312521</td>\n      <td>-0.000666</td>\n      <td>0.285729</td>\n      <td>0.110068</td>\n      <td>-0.008065</td>\n      <td>0.102690</td>\n      <td>0.218448</td>\n      <td>0.273025</td>\n      <td>0.532382</td>\n      <td>-0.312450</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.117288</td>\n      <td>-0.126811</td>\n      <td>-0.000619</td>\n      <td>0.109642</td>\n      <td>0.230750</td>\n      <td>0.272240</td>\n      <td>-0.040699</td>\n      <td>0.440407</td>\n      <td>0.173828</td>\n      <td>-0.013333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.088064</td>\n      <td>-0.010177</td>\n      <td>0.039213</td>\n      <td>-0.105073</td>\n      <td>-0.464175</td>\n      <td>0.165550</td>\n      <td>-0.085636</td>\n      <td>-0.486083</td>\n      <td>0.184655</td>\n      <td>0.122371</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.003085</td>\n      <td>0.340534</td>\n      <td>0.184257</td>\n      <td>-0.344518</td>\n      <td>0.000413</td>\n      <td>-0.457679</td>\n      <td>-0.179798</td>\n      <td>0.334319</td>\n      <td>0.014013</td>\n      <td>-0.048084</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.120189</td>\n      <td>-0.053361</td>\n      <td>0.002549</td>\n      <td>0.081047</td>\n      <td>0.074008</td>\n      <td>0.132922</td>\n      <td>-0.024197</td>\n      <td>-0.184508</td>\n      <td>0.065893</td>\n      <td>0.053854</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1720</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.134965</td>\n      <td>0.009408</td>\n      <td>-0.208372</td>\n      <td>-0.118267</td>\n      <td>0.111946</td>\n      <td>0.184245</td>\n      <td>0.199419</td>\n      <td>0.077554</td>\n      <td>0.102339</td>\n      <td>0.229039</td>\n    </tr>\n    <tr>\n      <th>1721</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.017197</td>\n      <td>0.063621</td>\n      <td>-0.208461</td>\n      <td>0.278269</td>\n      <td>0.035245</td>\n      <td>-0.191154</td>\n      <td>-0.037291</td>\n      <td>-0.075631</td>\n      <td>-0.166058</td>\n      <td>-0.197916</td>\n    </tr>\n    <tr>\n      <th>1722</th>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.292122</td>\n      <td>-0.107703</td>\n      <td>0.033369</td>\n      <td>-0.129890</td>\n      <td>0.117992</td>\n      <td>0.343188</td>\n      <td>-0.162703</td>\n      <td>0.123009</td>\n      <td>-0.177615</td>\n      <td>0.134538</td>\n    </tr>\n    <tr>\n      <th>1723</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.168297</td>\n      <td>-0.051984</td>\n      <td>-0.241973</td>\n      <td>0.068978</td>\n      <td>-0.117036</td>\n      <td>-0.083507</td>\n      <td>-0.025199</td>\n      <td>0.517580</td>\n      <td>0.146653</td>\n      <td>-0.223473</td>\n    </tr>\n    <tr>\n      <th>1724</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.110091</td>\n      <td>0.072627</td>\n      <td>0.110446</td>\n      <td>0.156720</td>\n      <td>-0.054317</td>\n      <td>-0.149864</td>\n      <td>0.203075</td>\n      <td>-0.032259</td>\n      <td>0.346316</td>\n      <td>-0.257093</td>\n    </tr>\n  </tbody>\n</table>\n<p>1725 rows × 74 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('latentdat_64.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}